{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "from scipy import optimize, ndimage\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T\n",
    "\n",
    "def split_Raman_af(X):\n",
    "    \"\"\"\n",
    "    Removing spikes from the data to extract the autofluorescence.\n",
    "    This is done by applying smoothing filter to the data and then taking the min of the smoothing filter and original data.\n",
    "    \"\"\"\n",
    "    a = X\n",
    "    # remove spikes from data\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 10), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 20), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 30), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 40), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 50), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "\n",
    "    a1 = ndimage.gaussian_filter(a, (0, 60), mode='nearest')\n",
    "    a = np.min([a, a1], axis=0)\n",
    "    \n",
    "    # Restore Edges\n",
    "    c = 50\n",
    "    a[:,:c] = X[:,:c]\n",
    "    a[:,-c:] = X[:,-c:]\n",
    "    \n",
    "    #smooth everyting\n",
    "    for _ in range(100):\n",
    "        a1 = ndimage.gaussian_filter(a, (0, 10), mode='nearest')\n",
    "        a = np.min([a, a1], axis=0)\n",
    "        a[:,0] = X[:,0]\n",
    "        a[:,-1] = X[:,-1]\n",
    "        \n",
    "    return X-a, a\n",
    "\n",
    "def smoothing(X, smooth=5, spike_width=3):\n",
    "    \"\"\"\n",
    "    Only remove noise from low noise to signal area's to maintain the intensity of the spikes.\n",
    "    Noise is removed with a gaussian filter in spectral dimension.\n",
    "    \"\"\"\n",
    "    grad = ndimage.gaussian_filter(X, (0, 1), order=1)\n",
    "    grad_abs = np.abs(grad)\n",
    "    grad_abs_sm = ndimage.gaussian_filter(grad_abs, (0, 1))\n",
    "    mean_grad = np.mean(grad_abs, 1) + np.std(grad_abs, 1)\n",
    "    noise_to_signal_quality = ndimage.gaussian_filter((grad_abs_sm.T < mean_grad).T.astype(float), (0, spike_width))\n",
    "    return noise_to_signal_quality * ndimage.gaussian_filter(X, (0,smooth)) + (1-noise_to_signal_quality) * X\n",
    "\n",
    "def stack_raman_lf(ram, fl):\n",
    "#     return unit_vector_norm(np.hstack((fl, ram)))    \n",
    "    return np.hstack((unit_vector_norm(fl), unit_vector_norm(ram)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Raman/blue0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-704ae5ef5aad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mref_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mref_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"../data/Raman/{file}.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Raman/blue0.npy'"
     ]
    }
   ],
   "source": [
    "wavelength = np.load(\"../data/Raman/wavelength.npy\", 'r')\n",
    "\n",
    "files = ['blue0', 'blue1', 'blue2', 'blue3', 'blue4',\n",
    "         'green0', 'green1', 'green2',\n",
    "         'red0', 'red1', 'red2']\n",
    "\n",
    "ref_vectors = {}\n",
    "for file in files:\n",
    "    ref_vectors[file] = np.load(f\"../data/Raman/{file}.npy\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.hstack((wavelength - 2000, wavelength))\n",
    "\n",
    "blue  = np.array([value for key, value in ref_vectors.items() if 'blue'  in key])\n",
    "red   = np.array([value for key, value in ref_vectors.items() if 'red'   in key])\n",
    "green = np.array([value for key, value in ref_vectors.items() if 'green' in key])\n",
    "    \n",
    "b  = smoothing(blue , 10, 25)\n",
    "r   = smoothing(red  , 5, 2)\n",
    "g = smoothing(green, 5, 2)\n",
    "\n",
    "blue  = stack_raman_lf(*split_Raman_af(b))\n",
    "red   = stack_raman_lf(*split_Raman_af(r))\n",
    "green = stack_raman_lf(*split_Raman_af(g))\n",
    "\n",
    "avg_b = np.mean(blue, 0)\n",
    "avg_r = np.mean(red, 0)\n",
    "avg_g = np.mean(green, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "for s in blue:\n",
    "    plt.plot(wave, s, 'b')\n",
    "    \n",
    "for s in red:\n",
    "    plt.plot(wave, s, 'r')\n",
    "    \n",
    "for s in green:\n",
    "    plt.plot(wave, s, 'g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "for s in b:\n",
    "    plt.plot(wavelength, s, 'b')\n",
    "                \n",
    "for s in r:\n",
    "    plt.plot(wavelength, s, 'r')\n",
    "    \n",
    "for s in g:\n",
    "    plt.plot(wavelength, s, 'g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "plt.plot(wave, avg_b, 'b')         \n",
    "plt.plot(wave, avg_r, 'r')\n",
    "plt.plot(wave, avg_g, 'g')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAVE = 2126 * 2\n",
    "\n",
    "# X = np.load(\"../data/Raman/Alina_art_1_1.npy\", 'r')\n",
    "Y = np.load(\"../data/Raman/Alina_Art_4_2.npy\", 'r')\n",
    "\n",
    "# shape_X = X.shape \n",
    "shape_Y = Y.shape\n",
    "\n",
    "# X = copy.copy(X.reshape(-1, X.shape[-1]))\n",
    "Y = copy.copy(Y.reshape(-1, Y.shape[-1]))\n",
    "\n",
    "# ram_X, afl_X = split_Raman_af(X)\n",
    "# ram_smooth_X = smoothing(ram_X, s)\n",
    "\n",
    "Y = smoothing(Y, 5, 2)\n",
    "ram_smooth_Y, fluor_smooth = split_Raman_af(Y)\n",
    "\n",
    "data = np.hstack((unit_vector_norm(fluor_smooth), unit_vector_norm(ram_smooth_Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceVectorClassifier(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def fit(self):\n",
    "        self.reference_spectra_ = self.kwargs['ref']\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "\n",
    "        # Input validation\n",
    "        X = unit_vector_norm(X)\n",
    "        \n",
    "        ###################### RCA ################################           \n",
    "        RCA_vector = np.array([optimize.nnls(self.reference_spectra_.T, X[i,:])[0] for i in range(X.shape[0])])\n",
    "\n",
    "        return RCA_vector\n",
    "    \n",
    "    def get_reference_vectors(self):\n",
    "        return self.reference_spectra_  \n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return self.kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_map(estimator, X, y=None):\n",
    "    RCA = estimator.predict(X)\n",
    "    ref_vec = estimator.get_reference_vectors()\n",
    "    return ((RCA @ ref_vec - X)**2).mean(1)\n",
    "\n",
    "def score_func(estimator, X, y=None):\n",
    "    X = unit_vector_norm(X)\n",
    "    return error_map(estimator, X).mean()\n",
    "\n",
    "def print_mean_std(X):\n",
    "    return f\"{X.mean():<12.4e}{X.std():<12.4e}\"\n",
    "\n",
    "def cross_val_X_Y_Z(rvc, X, Y, Z):\n",
    "    rvc.fit(np.concatenate((X, Y), axis=0))\n",
    "    return score_func(rvc, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'ref' : np.array([avg_r, avg_g, avg_b]),\n",
    "    'n_components': 3 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvc = ReferenceVectorClassifier(**kwargs)\n",
    "rvc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCA_vector = rvc.predict(data)\n",
    "\n",
    "print(\"fit score: \", score_func(rvc, data))\n",
    "RCA_vector = RCA_vector - RCA_vector.min(0)\n",
    "RCA_vector /= RCA_vector.max(0)\n",
    "\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.imshow(RCA_vector.reshape((*shape_Y[:2], kwargs['n_components']))[::-1,:,:3])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.imshow(error_map(rvc, data).reshape(shape_Y[:2]), cmap='gray', vmin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
