{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import inspect\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from scipy import optimize, ndimage\n",
    "from sklearn import decomposition, cluster, model_selection, metrics\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train\n",
    "\n",
    "import numpy.polynomial.polynomial as poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T\n",
    "\n",
    "def split_Raman_af(X):\n",
    "    \"\"\"\n",
    "    Removing spikes from the data to extract the autofluorescence.\n",
    "    This is done by applying smoothing filter to the data and then taking the min of the smoothing filter and original data.\n",
    "    \"\"\"\n",
    "    a = X\n",
    "    c = 50\n",
    "\n",
    "    # remove the top of the spikes from data, by using a Gaussian smoothing filter\n",
    "    for _ in range(5):      \n",
    "        a[:,c] = X[:,c]\n",
    "        a[:,-c] = X[:,-c]      \n",
    "        a1 = ndimage.gaussian_filter(a, (0, 30), mode='nearest')\n",
    "        a = np.min([a, a1], axis=0)\n",
    "\n",
    "    # remove the spikes from data, by using a polynominal fit\n",
    "    for _ in range(5):\n",
    "        a[:,c] = X[:,c]\n",
    "        a[:,-c] = X[:,-c]        \n",
    "        z = poly.polyfit(wavelength[::5], a[:,::5].T, 5)\n",
    "        a1 = poly.polyval(wavelength, z)\n",
    "        a = np.min([a, a1], axis=0)\n",
    "        \n",
    "    # smooth the curve the data, (to remove remnants of noise in the photoluminescence signal)\n",
    "    for _ in range(10):           \n",
    "        a[:,1] = X[:,1]\n",
    "        a[:,-1] = X[:,-1]         \n",
    "        a = ndimage.gaussian_filter(a, (0, 10), mode='nearest')\n",
    "\n",
    "    # make the Raman signal non-negative, (to remove remnants of noise in the Raman signal)\n",
    "    return (X-a).clip(min=0), a \n",
    "\n",
    "def smoothing(X, smooth=5, transition=10, spike_width=7):\n",
    "    \"\"\"\n",
    "    Only remove noise from low noise to signal area's to maintain the intensity of the spikes.\n",
    "    Noise is removed with a gaussian filter in spectral dimension.\n",
    "    \"\"\"\n",
    "    grad = ndimage.gaussian_filter(X, (0, 1), order=1)\n",
    "    grad_abs = np.abs(grad)\n",
    "    grad_abs_sm = ndimage.gaussian_filter(grad_abs, (0, 5))\n",
    "    mean_grad = np.mean(grad_abs, 1) + 1 / np.std(grad_abs, 1) * 3\n",
    "    \n",
    "    spikes = ((grad_abs_sm.T > mean_grad ).astype(float)).T \n",
    "    spikes = np.round(ndimage.gaussian_filter(spikes, (0, spike_width)))\n",
    "    spikes = ndimage.uniform_filter(spikes, (0, transition))\n",
    "    \n",
    "    return (1 - spikes) * ndimage.gaussian_filter(X, (0,smooth)) + spikes * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAVE = 2126\n",
    "\n",
    "X = np.load(\"../data/Raman/Alina_art_1_1.npy\", 'r')[:,:,2:N_WAVE+2]\n",
    "Y = np.load(\"../data/Raman/Alina_art_2_1.npy\", 'r')\n",
    "Z = np.load(\"../data/Raman/Alina_Art_4_2.npy\", 'r')\n",
    "\n",
    "wavelength = np.load(\"../data/Raman/wavelength.npy\", 'r')\n",
    "\n",
    "shape_X = X.shape \n",
    "shape_Y = Y.shape\n",
    "shape_Z = Z.shape \n",
    "\n",
    "X = copy.copy(X.reshape(-1, X.shape[-1]))\n",
    "X_smooth = smoothing(X)\n",
    "ram_X, afl_X = split_Raman_af(X_smooth)\n",
    "\n",
    "Y = copy.copy(Y.reshape(-1, Y.shape[-1]))\n",
    "Y_smooth = smoothing(Y)\n",
    "ram_Y, afl_Y = split_Raman_af(Y_smooth)\n",
    "\n",
    "Z = copy.copy(Z.reshape(-1, Z.shape[-1]))\n",
    "Z_smooth = smoothing(Z)\n",
    "ram_Z, afl_Z = split_Raman_af(Z_smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceVectorClassifierPCA(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        self.pca_kwargs = {}\n",
    "        self.k_means_kwargs = {}        \n",
    "        self.set_params(**kwargs)\n",
    "        \n",
    "    def fit(self, x, **kwargs):\n",
    "        self.set_params(**kwargs)\n",
    "        X = unit_vector_norm(x)\n",
    "        \n",
    "        ###################### clustering ################################\n",
    "        self.clusters = cluster.KMeans(**self.k_means_kwargs).fit(X)\n",
    "        self.clusters = self.clusters.labels_\n",
    "        \n",
    "        one_hot = np.zeros((X.shape[0], self.kwargs['n_clusters']), dtype=bool)\n",
    "        one_hot[range(X.shape[0]), self.clusters] = 1\n",
    "\n",
    "        ###################### reference spectra ################################  \n",
    "        self.reference_spectra_ = unit_vector_norm(np.array([np.abs(x_) for i, x_ in enumerate(one_hot.T @ X)]))\n",
    "        self.ref_org = np.array([x[one_hot[:,i],:].mean(axis=0) for i in range(self.kwargs['n_clusters'])])\n",
    "                     \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        X = unit_vector_norm(X)\n",
    "                \n",
    "        ###################### RCA ################################\n",
    "        RCA_vector = np.array([optimize.nnls(self.reference_spectra_.T, X[i,:])[0] for i in range(X.shape[0])])\n",
    "        \n",
    "        return RCA_vector  \n",
    "    \n",
    "    def get_reference_vectors(self):\n",
    "        return self.reference_spectra_\n",
    "    \n",
    "    def get_org_reference_vectors(self):\n",
    "        return self.ref_org\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return self.kwargs\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.kwargs.update(kwargs)\n",
    "        self.pca_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(decomposition.PCA).parameters.keys())})\n",
    "        self.k_means_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(cluster.KMeans).parameters.keys())})     \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_map(estimator, X, y=None):\n",
    "    RCA = estimator.predict(X)\n",
    "    ref_vec = estimator.get_reference_vectors()\n",
    "    return ((RCA @ ref_vec - X)**2).sum(1)\n",
    "\n",
    "def score_func(estimator, X, y=None):\n",
    "    tmp = np.sqrt((X**2).sum(axis=1))\n",
    "    X = unit_vector_norm(X)\n",
    "    return (error_map(estimator, X) * tmp).mean()\n",
    "\n",
    "def print_mean_std(X):\n",
    "    return f\"{X.mean():<12.4e}{X.std():<12.4e}\"\n",
    "\n",
    "def cross_val_X_Y_Z(rvc, X, Y, Z):\n",
    "    rvc.fit(np.concatenate((X, Y), axis=0))\n",
    "    return score_func(rvc, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'n_clusters': 3,\n",
    "          'n_components': 3,\n",
    "          'batch_size': 16,\n",
    "          'cuda': True,\n",
    "          'log_step': 10,\n",
    "          'epochs': 10,\n",
    "          'depth': 5,\n",
    "          'neurons': 500,\n",
    "          'bias': True\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    rvc = ReferenceVectorClassifierPCA(**kwargs)\n",
    "    rvc.fit(ram_X)\n",
    "    score.append(score_func(rvc, ram_X))   \n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))\n",
    "del score[np.argmax(score)]\n",
    "del score[np.argmin(score)]\n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    rvc = ReferenceVectorClassifierPCA(**kwargs)\n",
    "    rvc.fit(ram_Y)\n",
    "    score.append(score_func(rvc, ram_Y))\n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))\n",
    "del score[np.argmax(score)]\n",
    "del score[np.argmin(score)]\n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Elapsed time: 0h 1m 2s 140.917ms\n",
      "[39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133]\n",
      "39.68890234758133 0.0\n",
      "[39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133, 39.68890234758133]\n",
      "39.68890234758133 0.0\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "score = []\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    rvc = ReferenceVectorClassifierPCA(**kwargs)\n",
    "    rvc.fit(ram_Z)\n",
    "    score.append(score_func(rvc, ram_Z))\n",
    "end_time = datetime.now()\n",
    "time_diff = relativedelta(end_time, start_time)\n",
    "print('Elapsed time: {}h {}m {}s {}ms'.format(time_diff.hours, time_diff.minutes, time_diff.seconds, time_diff.microseconds/1000))\n",
    " \n",
    "    \n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))\n",
    "del score[np.argmax(score)]\n",
    "del score[np.argmin(score)]\n",
    "print(score)\n",
    "print(np.mean(score), np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit score:  354.06180907906787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = ram_X\n",
    "rvc = ReferenceVectorClassifierPCA(**kwargs)\n",
    "rvc.fit(test)\n",
    "RCA_vector = rvc.predict(test)\n",
    "\n",
    "print(\"fit score: \", score_func(rvc, test))\n",
    "\n",
    "RCA_vector = np.abs(RCA_vector)\n",
    "RCA_vector = RCA_vector - RCA_vector.min(0)\n",
    "RCA_vector /= RCA_vector.max(0)\n",
    "\n",
    "plt.figure(figsize = (20,6))\n",
    "plt.imshow(RCA_vector.reshape((*shape_X[:2], 3))[::-1,:,(2,1,0)])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
