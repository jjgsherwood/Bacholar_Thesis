{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-374d630a5cdd>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-374d630a5cdd>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    import ../utils.dataset_utils as dataset\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import inspect\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from scipy import optimize, ndimage\n",
    "from sklearn import decomposition, cluster, model_selection, metrics\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothing2(X, smooth=5, spike_width=3):\n",
    "    \"\"\"\n",
    "    Only remove noise from low noise to signal area's to maintain the intensity of the spikes.\n",
    "    Noise is removed with a gaussian filter in spectral dimension.\n",
    "    \"\"\"\n",
    "    grad = ndimage.gaussian_filter(X, (0, 1), order=1)\n",
    "    grad_abs = np.abs(grad)\n",
    "    grad_abs_sm = ndimage.gaussian_filter(grad_abs, (0, 1))\n",
    "    mean_grad = np.mean(grad_abs, 1) + np.std(grad_abs, 1)\n",
    "    noise_to_signal_quality = ndimage.gaussian_filter((grad_abs_sm.T < mean_grad).T.astype(float), (0, spike_width))\n",
    "    return noise_to_signal_quality * ndimage.gaussian_filter(X, (0,smooth)) + (1-noise_to_signal_quality) * X\n",
    "\n",
    "\n",
    "def smoothing(X, smooth=5, transition=10, spike_width=7):\n",
    "    \"\"\"\n",
    "    Only remove noise from low noise to signal area's to maintain the intensity of the spikes.\n",
    "    Noise is removed with a gaussian filter in spectral dimension.\n",
    "    \"\"\"\n",
    "    grad = ndimage.gaussian_filter(X, (0, 1), order=1)\n",
    "    grad_abs = np.abs(grad)\n",
    "    grad_abs_sm = ndimage.gaussian_filter(grad_abs, (0, 5))\n",
    "    mean_grad = np.mean(grad_abs, 1) + 1 / np.std(grad_abs, 1) * 3\n",
    "    \n",
    "    spikes = ((grad_abs_sm.T > mean_grad ).astype(float)).T \n",
    "    spikes = np.round(ndimage.gaussian_filter(spikes, (0, spike_width)))\n",
    "    spikes = ndimage.uniform_filter(spikes, (0, transition))\n",
    "    \n",
    "    i = 5458\n",
    "    i = 5703\n",
    "#     i = 4563\n",
    "\n",
    "    plt.figure(figsize = (10,6), dpi=500)\n",
    "    plt.plot(wavelength, X[i], label='raw data', alpha=0.5)\n",
    "    plt.plot(wavelength, grad_abs_sm[i]*5, label='absoluut gradient', alpha=0.7)\n",
    "    plt.plot(wavelength, spikes[i]*100, label='p(Raman spikes)')\n",
    "#     plt.plot([0,3000], [mean_grad[i]*15, mean_grad[i]*15], '--r')\n",
    "    plt.xlabel(\"wavenumber ($cm^{-1}$)\", fontsize=14)\n",
    "    plt.ylabel(\"Intensity(-) / probablity(%)\", fontsize=14)\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([80,1600])\n",
    "    axes.set_ylim([0,450])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return (1 - spikes) * ndimage.gaussian_filter(X, (0,smooth)) + spikes * X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAVE = 2126\n",
    "\n",
    "Y = np.load(\"../data/Raman/Alina_Art_4_2.npy\", 'r')\n",
    "\n",
    "wavelength = np.load(\"../data/Raman/wavelength.npy\", 'r')\n",
    "shape_Y = Y.shape\n",
    "\n",
    "Y = copy.copy(Y.reshape(-1, Y.shape[-1]))\n",
    "Ram = smoothing(Y, 5, 10, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i = random.randint(0, 6026)\n",
    "i = 5703\n",
    "# i = 4563\n",
    "plt.figure(figsize = (10,6), dpi=500)\n",
    "plt.plot(wavelength, Y[i], label='raw_raman_'+str(i), alpha=0.4)\n",
    "plt.plot(wavelength, Ram[i], label='Raman', alpha=1)\n",
    "plt.plot(wavelength, Y[i]-Ram[i], label='noise')\n",
    "plt.xlabel(\"wavenumber ($cm^{-1}$)\", fontsize=14)\n",
    "plt.ylabel(\"Intensity(-)\", fontsize=14)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([80,1600])\n",
    "axes.set_ylim([-20,400])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
