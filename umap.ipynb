{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import sklearn.datasets\n",
    "import umap\n",
    "import umap.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"../data/\", train=True, download=True, transform=transforms.ToTensor())\n",
    "test = datasets.MNIST(\"../data/\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IM_SIZE = 28 * 28\n",
    "IM_SHAPE = (28, 28)\n",
    "CPU_training = False\n",
    "BATCH = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "use_cuda =  torch.cuda.is_available() and not CPU_training\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=BATCH, shuffle=True, num_workers=6, pin_memory=use_cuda)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=BATCH, shuffle=True, num_workers=6, pin_memory=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(IM_SIZE, dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(dim, IM_SIZE),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(IM_SIZE, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, dim),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, IM_SIZE),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class AutoEncoderConv(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.encoder_conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.encoder_conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, return_indices=True)\n",
    "            \n",
    "        self.encoder_full = nn.Sequential( \n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*6*6, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(0.5),\n",
    "            nn.Linear(64, dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder_full = nn.Sequential(\n",
    "            nn.Linear(dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 64*6*6),\n",
    "            View((-1,64,6,6))\n",
    "        )\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(4)\n",
    "        \n",
    "        self.decoder_conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder_conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 1, 3),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        x = self.encoder_conv1(x)\n",
    "        x, self.indices1 = self.pool(x)\n",
    "        x = self.encoder_conv2(x)\n",
    "        x, self.indices2 = self.pool(x)        \n",
    "        return self.encoder_full(x)\n",
    "    \n",
    "    def decoder(self, x):\n",
    "        x = self.decoder_full(x)\n",
    "        x = self.unpool(x, self.indices2)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.unpool(x, self.indices1)        \n",
    "        return self.decoder_conv2(x)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, dim):\n",
    "    net = network(dim).to(device).train()\n",
    "\n",
    "#     optimizer = optim.Adadelta(net.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#     scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        for X, _ in trainset:\n",
    "            if not isinstance(net, AutoEncoderConv):\n",
    "                X = X.view(-1, IM_SIZE)\n",
    "            X = X.to(device)\n",
    "            net.zero_grad()\n",
    "            output = net(X)\n",
    "            loss = F.binary_cross_entropy(output, X)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#         scheduler.step()\n",
    "        print(epoch, loss)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    net.eval()\n",
    "\n",
    "    comp_data = np.empty((10000, net.dim))\n",
    "    comp_label = np.empty((10000,))\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(testset):\n",
    "            if not isinstance(net, AutoEncoderConv):\n",
    "                X = X.view(-1, IM_SIZE)\n",
    "            X = X.to(device)\n",
    "            latent = net.encoder(X)\n",
    "            output = net.decoder(latent)\n",
    "            comp_data[BATCH * i: BATCH * (i + 1)] = latent.cpu()\n",
    "            comp_label[BATCH * i: BATCH * (i + 1)] = y\n",
    "\n",
    "            loss += F.mse_loss(output, X)\n",
    "\n",
    "    print(loss / (i + 1))\n",
    "    if use_cuda:\n",
    "        X = X.cpu()\n",
    "        output = output.cpu()\n",
    "        \n",
    "    plt.subplot(141)\n",
    "    plt.imshow(X[0].view(IM_SHAPE))\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(output[0].view(IM_SHAPE))\n",
    "    plt.subplot(143)\n",
    "    plt.scatter(comp_data[0:-1:5,0], comp_data[0:-1:5,1], c=comp_label[0:-1:5], cmap=plt.cm.rainbow)\n",
    "    plt.subplot(144)\n",
    "    plt.scatter(comp_data[0:-1:5,2], comp_data[0:-1:5,3], c=comp_label[0:-1:5], cmap=plt.cm.rainbow)    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return comp_data, comp_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_pca = train(PCA, 16)\n",
    "# X_pca, y_pca = test(net_pca)\n",
    "# mapper = umap.UMAP(n_neighbors=15, n_components=2, metric='correlation', min_dist=0.15).fit(X_pca)\n",
    "# umap.plot.points(mapper, labels=y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_auto = train(AutoEncoder, 16)\n",
    "# X_auto, y_auto = test(net_auto)\n",
    "# mapper = umap.UMAP(n_neighbors=15, n_components=2, metric='correlation', min_dist=0.15).fit(X_auto)\n",
    "# umap.plot.points(mapper, labels=y_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2595, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    }
   ],
   "source": [
    "net_conv = train(AutoEncoder, 16)\n",
    "X_conv, y_conv = test(net_conv)\n",
    "mapper = umap.UMAP(n_neighbors=25, n_components=2, metric='correlation', min_dist=0.05).fit(X_conv)\n",
    "umap.plot.points(mapper, labels=y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
