{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_array, check_is_fitted\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import inspect\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from scipy import optimize, ndimage\n",
    "from sklearn import decomposition, cluster, model_selection, metrics\n",
    "import sklearn\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils.dataset_utils as dataset\n",
    "import utils.train_utils as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_norm(X):\n",
    "    X -= X.min() #remove noise offset\n",
    "    return (X.T / np.sqrt((X**2).sum(axis=1))).T\n",
    "\n",
    "def blur_norm(X, s):\n",
    "    return ndimage.gaussian_filter(X, (s,s,0))\n",
    "\n",
    "def mu_norm(X):\n",
    "    return X - X.mean(0)\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 368 to 1750\n",
    "N_WAVE = 700\n",
    "s = 1\n",
    "start_index, end_index = 115, 815\n",
    "\n",
    "X = blur_norm(np.load(\"../data/HSI/Liver_map_150z25_60s_1TCPOBOP.npy\", 'r')[:,:,start_index: end_index], s)\n",
    "Y = blur_norm(np.load(\"../data/HSI/Liver_map_150z25_60s_2TCPOBOP.npy\", 'r')[:,:,start_index: end_index], s)\n",
    "Z = blur_norm(np.load(\"../data/HSI/Liver_map_150z25_60s_3OBOB.npy\", 'r')[:,:,start_index: end_index], s)\n",
    "wavelength = np.load(\"../data/HSI/wavelength.npy\", 'r')[start_index: end_index]\n",
    "\n",
    "shape_X = X.shape \n",
    "shape_Y = Y.shape \n",
    "shape_Z = Z.shape \n",
    "\n",
    "X = copy.copy(X.reshape(-1, X.shape[-1]))\n",
    "Y = copy.copy(Y.reshape(-1, Y.shape[-1]))\n",
    "Z = copy.copy(Z.reshape(-1, Z.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderConv(nn.Module):\n",
    "    def __init__(self, n_components=10, depth=2, neurons=100, bias=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encode = nn.Sequential( \n",
    "            nn.Dropout3d(0.25),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(N_WAVE, neurons, bias=bias),\n",
    "            nn.ReLU(True),\n",
    "            *((nn.Linear(neurons, neurons, bias=bias),\n",
    "            nn.ReLU(True)) * (depth-1)),\n",
    "            nn.Linear(neurons, n_components, bias=bias),\n",
    "        )\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(n_components, neurons, bias=bias),\n",
    "            nn.ReLU(True),\n",
    "            *((nn.Linear(neurons, neurons, bias=bias),\n",
    "            nn.ReLU(True)) * (depth-1)),            \n",
    "            nn.Linear(neurons, N_WAVE, bias=bias),\n",
    "            View((-1,1,1,1,N_WAVE))\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.decode(self.encode(x))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE_loss(x, model):\n",
    "    W = model.encode(x)\n",
    "    x_ = model.decode(W)\n",
    "\n",
    "#     print(torch.abs(W @ W.T))\n",
    "#     print((torch.abs(W @ W.T).sum() - W.size(0)) / (W.size(0)**2 - W.size(0)))\n",
    "    \n",
    "    # maximize the difference in reference vectors\n",
    "    reference_spectra_ = (W.T @ x.squeeze())\n",
    "    reference_spectra_ = (reference_spectra_.T / torch.sqrt((reference_spectra_**2).sum(axis=1))).T\n",
    "#     print(reference_spectra_)\n",
    "    max_ref_diff = ((torch.abs(reference_spectra_ @ reference_spectra_.T).sum() - reference_spectra_.size(0)) / (reference_spectra_.size(0)**2 - reference_spectra_.size(0)))\n",
    "#     print(reference_spectra_ @ reference_spectra_.T)\n",
    "    for i in range(W.size(1)):\n",
    "        for j in range(i + 1, W.size(1)):\n",
    "            max_ref_diff += 1 / (torch.abs(reference_spectra_[i] - reference_spectra_[j]).sum() + 0.5)\n",
    "    max_ref_diff /= (W.size(1) * (W.size(1) - 1)) // 2 #number of combinations\n",
    "  \n",
    "    #smoothness loss on x1 and x2\n",
    "    smooth_x1 = torch.abs((x_[:, :, :, :, :-3] - x_[:, :, :, :, 3:])).mean()\n",
    "    smooth_x2 = torch.abs((x_[:, :, :, :, :-5] - x_[:, :, :, :, 5:])).mean()\n",
    "    smooth_x3 = torch.abs((x_[:, :, :, :, :-2] - x_[:, :, :, :, 2:])).mean()\n",
    "    smooth_x4 = torch.abs((x_[:, :, :, :, :-8] - x_[:, :, :, :, 8:])).mean()\n",
    "\n",
    "    e = ((F.relu(x_ - x))).sum(4).mean() + ((F.relu(-x_))).sum(4).mean()\n",
    "    \n",
    "    #MSE loss\n",
    "    MSE = ((x_ - x)**2).sum(4).mean()  \n",
    "    \n",
    "    return MSE + max_ref_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReferenceVectorClassifierAE(BaseEstimator):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = {}\n",
    "        self.k_means_kwargs = {}\n",
    "        self.ae_kwargs = {}        \n",
    "        self.set_params(**kwargs)\n",
    "\n",
    "        _use_cuda = torch.cuda.is_available() and kwargs['cuda']\n",
    "        if _use_cuda:\n",
    "            torch.backends.cudnn.enabled = True\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device('cuda' if _use_cuda else 'cpu')        \n",
    "        \n",
    "    def fit(self, x, **kwargs):\n",
    "        self.set_params(**kwargs)\n",
    "        X = unit_vector_norm(x)\n",
    "        \n",
    "        ###################### Autoencoder ################################\n",
    "        self.model = AutoEncoderConv(**self.ae_kwargs).to(self.device)\n",
    "        \n",
    "        parameters = filter(lambda x: x.requires_grad, self.model.parameters())\n",
    "        self.optimizer = optim.Adam(parameters)        \n",
    "        train_loader, test_loader = dataset.load_liver(X, self.kwargs['batch_size'])\n",
    "        \n",
    "        for epoch in range(self.kwargs['epochs']):\n",
    "            print('-'*50)\n",
    "            print('Epoch {:3d}/{:3d}'.format(epoch+1, self.kwargs['epochs']))\n",
    "            start_time = datetime.now()\n",
    "            train.train(self.model, self.optimizer, train_loader, self.kwargs['loss_func'], self.kwargs['log_step'], self.device)\n",
    "            end_time = datetime.now()\n",
    "            time_diff = relativedelta(end_time, start_time)\n",
    "            print('Elapsed time: {}h {}m {}s'.format(time_diff.hours, time_diff.minutes, time_diff.seconds))\n",
    "            loss = train.test(self.model, test_loader, self.kwargs['loss_func'], self.device)\n",
    "            print('Validation| bits: {:2.2f}'.format(loss), flush=True)    \n",
    "          \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            W = self.model.encode(dataset.load_liver_all(X).to(self.device))\n",
    "        self.z = W\n",
    "        W = W.cpu().detach().numpy()\n",
    "                   \n",
    "        ###################### reference spectra ################################\n",
    "#         W = W * (W > 0) #relu\n",
    "        self.reference_spectra_ = unit_vector_norm(W.T @ X)    \n",
    "        self.ref_org = unit_vector_norm(W.T @ x)\n",
    "                \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        predict transforms the data into the reference space. Min weight should be 0 or higher then 'min_weight'\n",
    "        The error is the NMSE, where the MSE is normalised by the signal strength. \n",
    "        error.shape = X.shape[0], so for each data point the error is calculated.\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "\n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        X = unit_vector_norm(X)\n",
    "        \n",
    "        ###################### RCA ################################           \n",
    "        RCA_vector = np.array([optimize.nnls(self.reference_spectra_.T, X[i,:])[0] for i in range(X.shape[0])])\n",
    "\n",
    "        return RCA_vector\n",
    "    \n",
    "    def get_reference_vectors(self):\n",
    "        return self.reference_spectra_\n",
    "\n",
    "    def get_org_reference_vectors(self):\n",
    "        return self.ref_org    \n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return self.kwargs\n",
    "    \n",
    "    def set_params(self, **kwargs):\n",
    "        self.kwargs.update(kwargs)\n",
    "        self.k_means_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(cluster.KMeans).parameters.keys())})     \n",
    "        self.ae_kwargs.update({k:v  for k,v in kwargs.items() if k in list(inspect.signature(AutoEncoderConv).parameters.keys())})     \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_map(estimator, X, y=None):\n",
    "    RCA = estimator.predict(X)\n",
    "    ref_vec = estimator.get_reference_vectors()\n",
    "    return ((RCA @ ref_vec - X)**2).mean(1)\n",
    "\n",
    "def score_func(estimator, X, y=None):\n",
    "    X = unit_vector_norm(X)\n",
    "    return error_map(estimator, X).mean()\n",
    "\n",
    "def print_mean_std(X):\n",
    "    return f\"{X.mean():<12.4e}{X.std():<12.4e}\"\n",
    "\n",
    "def cross_val_X_Y_Z(rvc, X, Y, Z):\n",
    "    rvc.fit(np.concatenate((X, Y), axis=0))\n",
    "    return score_func(rvc, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "kwargs = {'n_clusters': n,\n",
    "          'n_components': n,\n",
    "          'min_weight': 0,\n",
    "          'batch_size': 64,\n",
    "          'cuda': True,\n",
    "          'log_step': 10,\n",
    "          'loss_func': MSE_loss,\n",
    "          'epochs': 5,\n",
    "          'depth': 3,\n",
    "          'neurons': 30,\n",
    "          'bias': True\n",
    "         }\n",
    "\n",
    "header = f\"{'mean':12}{'std':12}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Epoch   1/  5\n",
      "  2020-06-05 15:57:27|     0/   52| bits: 12.69\n",
      "  2020-06-05 15:57:27|    10/   52| bits: 7.76\n",
      "  2020-06-05 15:57:27|    20/   52| bits: 5.90\n",
      "  2020-06-05 15:57:27|    30/   52| bits: 4.06\n",
      "  2020-06-05 15:57:27|    40/   52| bits: 2.55\n",
      "  2020-06-05 15:57:27|    50/   52| bits: 2.07\n",
      "Elapsed time: 0h 0m 2s\n",
      "Validation| bits: 2.01\n",
      "--------------------------------------------------\n",
      "Epoch   2/  5\n",
      "  2020-06-05 15:57:31|     0/   52| bits: 1.99\n",
      "  2020-06-05 15:57:31|    10/   52| bits: 1.51\n",
      "  2020-06-05 15:57:31|    20/   52| bits: 1.23\n",
      "  2020-06-05 15:57:31|    30/   52| bits: 1.00\n",
      "  2020-06-05 15:57:32|    40/   52| bits: 0.91\n",
      "  2020-06-05 15:57:32|    50/   52| bits: 0.61\n",
      "Elapsed time: 0h 0m 2s\n",
      "Validation| bits: 0.74\n",
      "--------------------------------------------------\n",
      "Epoch   3/  5\n",
      "  2020-06-05 15:57:35|     0/   52| bits: 0.66\n",
      "  2020-06-05 15:57:36|    10/   52| bits: 0.71\n",
      "  2020-06-05 15:57:36|    20/   52| bits: 0.59\n",
      "  2020-06-05 15:57:36|    30/   52| bits: 0.91\n",
      "  2020-06-05 15:57:36|    40/   52| bits: 0.95\n",
      "  2020-06-05 15:57:36|    50/   52| bits: 0.93\n",
      "Elapsed time: 0h 0m 2s\n",
      "Validation| bits: 0.93\n",
      "--------------------------------------------------\n",
      "Epoch   4/  5\n",
      "  2020-06-05 15:57:40|     0/   52| bits: 0.82\n",
      "  2020-06-05 15:57:40|    10/   52| bits: 0.87\n",
      "  2020-06-05 15:57:40|    20/   52| bits: 0.78\n",
      "  2020-06-05 15:57:40|    30/   52| bits: 0.64\n",
      "  2020-06-05 15:57:40|    40/   52| bits: 0.56\n",
      "  2020-06-05 15:57:41|    50/   52| bits: 0.92\n",
      "Elapsed time: 0h 0m 2s\n",
      "Validation| bits: 0.79\n",
      "--------------------------------------------------\n",
      "Epoch   5/  5\n"
     ]
    }
   ],
   "source": [
    "rvc = ReferenceVectorClassifierAE(**kwargs)\n",
    "rvc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCA_vector = rvc.predict(X)\n",
    "\n",
    "print(\"fit score: \", score_func(rvc, X))\n",
    "\n",
    "RCA_vector = RCA_vector - RCA_vector.min(0)\n",
    "RCA_vector /= RCA_vector.max(0)\n",
    "plt.figure(figsize = (20,4))\n",
    "plt.imshow(np.swapaxes(RCA_vector.reshape((*shape_X[:2], kwargs['n_clusters'])),0,1)[::-1,:,:3])\n",
    "plt.show()\n",
    "# plt.figure(figsize = (20,4))\n",
    "# plt.imshow(np.swapaxes(RCA_vector.reshape((*shape_X[:2], kwargs['n_clusters'])),0,1)[::-1,:,3:6])\n",
    "# plt.show()\n",
    "# plt.figure(figsize = (20,4))\n",
    "# plt.imshow(np.swapaxes(RCA_vector.reshape((*shape_X[:2], kwargs['n_clusters'])),0,1)[::-1,:,6:9])\n",
    "# plt.show()\n",
    "plt.figure(figsize = (20,4))\n",
    "plt.imshow(error_map(rvc, X).reshape(shape_X[:2]).T, cmap='gray', vmin=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,12))\n",
    "for i, r in enumerate(rvc.get_reference_vectors()):\n",
    "    plt.plot(wavelength, r, label=i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructing plot\n",
    "with torch.no_grad():\n",
    "    x_ = rvc.model(dataset.load_liver_all(unit_vector_norm(X)).to('cuda:0'))\n",
    "\n",
    "plt.figure(figsize = (20,12))\n",
    "\n",
    "for i in range(0,1000,10):\n",
    "    plt.plot(wavelength, x_[i].flatten().cpu().detach().numpy(),label='rec')\n",
    "#     plt.plot(wavelength, unit_vector_norm(X)[i] , label='org')    \n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = rvc.z.mean(0)\n",
    "sigma = rvc.z.std(0)\n",
    "mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu plot\n",
    "plt.figure(figsize = (20,12))\n",
    "plt.plot(wavelength, rvc.model.decode(mu).flatten().cpu().detach().numpy(), label='centre_z')\n",
    "plt.plot(wavelength, unit_vector_norm(X).mean(0), label='centre') \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct = torch.squeeze(rvc.model.decode(torch.eye(rvc.kwargs['n_components']).to(rvc.device)*sigma*3)).cpu().detach().numpy()\n",
    "\n",
    "print(rvc.z[0])\n",
    "\n",
    "plt.figure(figsize = (20,12))\n",
    "for i, r in enumerate(reconstruct):\n",
    "    plt.plot(wavelength, r, label=i)\n",
    "plt.plot(wavelength, unit_vector_norm(X).mean(0),label='centre')    \n",
    "plt.plot(wavelength, unit_vector_norm(X)[0],label='org')    \n",
    "plt.plot(wavelength, a[0].flatten().cpu().detach().numpy(),label='rec')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rvc.z[:,0].flatten().cpu().detach().numpy(), rvc.z[:,1].flatten().cpu().detach().numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rvc.z[:,2].flatten().cpu().detach().numpy(), rvc.z[:,3].flatten().cpu().detach().numpy(), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rvc.z.mean(0))\n",
    "# print(rvc.z.std(0))\n",
    "\n",
    "# plt.figure(figsize = (20,12))\n",
    "# for i in range(0,3750,100):\n",
    "#     plt.plot(rvc.z[i].cpu().detach().numpy())\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
